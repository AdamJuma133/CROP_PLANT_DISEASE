{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamJuma133/CROP_PLANT_DISEASE/blob/main/Crop_Plant_Disease_Identifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z83tLbEFdix"
      },
      "source": [
        "# Crop Disease Identifier System_AI_Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfxyYV_VIYoR"
      },
      "source": [
        "#1. Project Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRzXlRvHF8Pr"
      },
      "source": [
        "This project aims to develop a multiclass crop-plant-disease-identifier using a Convolutional Neural Network (CNN) model implemented in a Google Colab notebook. The dataset contains 13 different types of crops, each with healthy and unhealthy leaf classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l96ey_khFCRG",
        "outputId": "8a4510c2-df92-4fb4-ae9c-834b1d4eb421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP4R2YOnIuwp"
      },
      "source": [
        "1. Exploration\n",
        "\n",
        "1.1 Design Ideation\n",
        "\n",
        "1.2 Data sourcing from Google Drive\n",
        "\n",
        "1.3 Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-vc8cgxKBkL"
      },
      "source": [
        "\n",
        "2. Model Selection\n",
        "\n",
        "2.1 Provide pre-trained models\n",
        "\n",
        "2.2 Compare performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3IBgumkKaQM"
      },
      "source": [
        "\n",
        "3. Model Training\n",
        "\n",
        "3.1 Data split\n",
        "\n",
        "3.2 Transfer learning\n",
        "\n",
        "3.3bEvaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nUtyQ9Mj2yC"
      },
      "source": [
        "# 3. Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRgTVG4gv02L"
      },
      "source": [
        "Design Ideation\n",
        "\n",
        "\n",
        "The goal of this project is to develop a multiclass crop-plant-disease identifier using a Convolutional Neural Network (CNN) model. The dataset contains 13 different types of crops, each with healthy and unhealthy leaf classes. The project will be implemented in a Google Colab notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHERpWK8wQnZ"
      },
      "source": [
        "Data Sourcing\n",
        "\n",
        "The dataset is stored in Google Drive in a folder named PROJECT_CPDI. Within this folder, there are 13 subfolders, each containing its respective crop dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d233GSFmx3xi"
      },
      "source": [
        "Data Preparation\n",
        "\n",
        "1. Connect to Google Drive:\n",
        "\n",
        "  • Mount Google Drive to access the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP9wHeuo06bf"
      },
      "source": [
        "2. Organize Dataset:\n",
        "\n",
        "  • Ensure the dataset is properly organized into subfolders for each crop type and their respective healthy and unhealthy leaf classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUK_oDZn2a1N"
      },
      "source": [
        "3. Image Data Generators:\n",
        "\n",
        " •Use ImageDataGenerator from TensorFlow/Keras to preprocess and augment the images for training and validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRuQE-vX3j04"
      },
      "source": [
        "4. Data Splitting:\n",
        "\n",
        " •Split the data into training and validation sets using an 80-20 split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "F84CQmecNPrS"
      },
      "outputs": [],
      "source": [
        "# Exploration\n",
        "\n",
        "## Import Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ikxiT7d0NYGG"
      },
      "outputs": [],
      "source": [
        "## Connect to Google Drivefrom google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Chj7MtPVNkgY"
      },
      "outputs": [],
      "source": [
        "# Set Dataset Path\n",
        "DATASET_PATH = '/ https://drive.google.com/drive/folders/1T4Ye1kEe93H9BXj-GpOfDoL1DEYXkluu?usp=drive_link '"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKpR9FWwNy1d",
        "outputId": "9e21a818-e7af-4e6f-e679-01b7ec2c7af9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 31451 images belonging to 3 classes.\n",
            "Found 7861 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "# Set Dataset Path\n",
        "DATASET_PATH = '/content/drive/MyDrive/Crop_disease_Identifier_dataset '  # Assuming your dataset is in a folder named PROJECT_CPDI in your Google Drive\n",
        "\n",
        "# Data Preparation\n",
        "\n",
        "# Image Data Generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "oGrC3f-PFwgx"
      },
      "outputs": [],
      "source": [
        "# Set Dataset Path\n",
        "DATASET_PATH = '/https://drive.google.com/drive/folders/1T4Ye1kEe93H9BXj-GpOfDoL1DEYXkluu ' # Removed extra forward slash from path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy0qWQY--MNn"
      },
      "source": [
        "# Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thCRT3kU-ofD"
      },
      "source": [
        "Compare Performance\n",
        "\n",
        "\n",
        "We will compare the performance of VGG16 and ResNet50 models on the validation set. The comparison will be based on the validation accuracy and loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGnLW1Gl-Z77"
      },
      "source": [
        "Provide Pre-trained Models\n",
        "\n",
        "\n",
        "We will use pre-trained models VGG16 and ResNet50 for transfer learning. These models are widely used for image classification tasks and have shown good performance on various datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "230bbbbe-44f4-4147-abd9-7ecdb4825d7f",
        "id": "eFFw91L-dtxJ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/CROP_PLANT_DISEASE_IDENTIFIER(PROJECT CPDI)'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3850030196.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Image Data Generators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtrain_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/CROP_PLANT_DISEASE_IDENTIFIER(PROJECT CPDI)'"
          ]
        }
      ],
      "source": [
        "# Model Selection\n",
        "\n",
        "## Import Libraries\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator #Importing ImageDataGenerator\n",
        "import os #Importing OS\n",
        "\n",
        "\n",
        "## Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set Dataset Path\n",
        "DATASET_PATH = '/content/drive/MyDrive/CROP_PLANT_DISEASE_IDENTIFIER(PROJECT CPDI)'  # Assuming your dataset is in a folder named PROJECT_CPDI in your Google Drive\n",
        "\n",
        "# Data Preparation\n",
        "\n",
        "# Image Data Generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "## Load Pre-trained Models\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "resnet50_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "## Build Models\n",
        "def build_model(base_model):\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "vgg16_model = build_model(vgg16_base)\n",
        "resnet50_model = build_model(resnet50_base)\n",
        "\n",
        "## Compile Models\n",
        "# Increased learning rate for faster training\n",
        "vgg16_model.compile(optimizer=Adam(learning_rate=0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "resnet50_model.compile(optimizer=Adam(learning_rate=0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "## Compare Performance\n",
        "# Reduced number of batches to 5 per epoch\n",
        "history_vgg16 = vgg16_model.fit(train_generator, validation_data=validation_generator, epochs=10, steps_per_epoch=5)\n",
        "history_resnet50 = resnet50_model.fit(train_generator, validation_data=validation_generator, epochs=10, steps_per_epoch=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XgJJXsjHaAm"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Load Pre-trained Models\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "resnet50_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14wzLUaNHbYt"
      },
      "outputs": [],
      "source": [
        "## Build Models\n",
        "def build_model(base_model):\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "vgg16_model = build_model(vgg16_base)\n",
        "resnet50_model = build_model(resnet50_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STFdypk8HcSD"
      },
      "outputs": [],
      "source": [
        "##Compile Models\n",
        "vgg16_model.compile(optimizer=Adam(learning_rate=0.02), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "resnet50_model.compile(optimizer=Adam(learning_rate=0.02), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIvyjSICHdGB"
      },
      "outputs": [],
      "source": [
        "# Model Selection\n",
        "\n",
        "## Import Libraries\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d7_btAFHd1w"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5QI52gFHemB"
      },
      "outputs": [],
      "source": [
        "## Load Pre-trained Models\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "resnet50_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cw4aTTH2Il7u"
      },
      "outputs": [],
      "source": [
        "## Build Models\n",
        "def build_model(base_model):\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "vgg16_model = build_model(vgg16_base)\n",
        "resnet50_model = build_model(resnet50_base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zrfctawAIZh"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_3cbgAOBK8e"
      },
      "outputs": [],
      "source": [
        "# Model Training\n",
        "\n",
        "## Import Libraries\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "## Build Models\n",
        "def build_model(base_model):\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "vgg16_model = build_model(vgg16_base)\n",
        "resnet50_model = build_model(resnet50_base)\n",
        "\n",
        "## Compile Models\n",
        "vgg16_model.compile(optimizer=Adam(learning_rate=0.0002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "resnet50_model.compile(optimizer=Adam(learning_rate=0.0002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "## Train Models\n",
        "history_vgg16 = vgg16_model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
        "history_resnet50 = resnet50_model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
        "\n",
        "## Evaluate the Best Model\n",
        "best_model = vgg16_model if max(history_vgg16.history['val_accuracy']) > max(history_resnet50.history['val_accuracy']) else resnet50_model\n",
        "\n",
        "# Evaluate the best model\n",
        "evaluation = best_model.evaluate(validation_generator)\n",
        "\n",
        "print(f\"Validation Loss: {evaluation[0]}\")\n",
        "print(f\"Validation Accuracy: {evaluation[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtloIAMFAOiz"
      },
      "source": [
        "Data Split\n",
        "\n",
        "The data has already been split into training and validation sets using an 80-20 split during the data preparation step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqK3Ali0Afzv"
      },
      "source": [
        "Transfer Learning\n",
        "\n",
        "We use transfer learning with pre-trained models VGG16 and ResNet50. The models are fine-tuned on our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nAzaKNMAp3G"
      },
      "source": [
        "Evaluation\n",
        "\n",
        "We evaluate the models based on their validation accuracy and loss. The best model is selected for further use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcbG29fqJpLe"
      },
      "outputs": [],
      "source": [
        "## Load Pre-trained Models\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "resnet50_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy and loss\n",
        "def plot_history(history, title):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "# Plot the history of VGG16\n",
        "plot_history(history_vgg16, 'VGG16 Model')\n",
        "\n",
        "# Plot the history of ResNet50\n",
        "plot_history(history_resnet50, 'ResNet50 Model')"
      ],
      "metadata": {
        "id": "_DWWnDHkudhK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}